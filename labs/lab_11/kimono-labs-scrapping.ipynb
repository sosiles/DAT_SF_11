{
 "metadata": {
  "name": "",
  "signature": "sha256:01dc5b237a6a3159fbaa1da258024a12c2d5b5ab58d388c081619c8416552160"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Web scraping with the Kimono Labs API\n",
      "\n",
      "https://www.kimonolabs.com/"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Datasets we will explore - \n",
      "\n",
      "* https://news.ycombinator.com/jobs\n",
      "* http://sfbay.craigslist.org/search/apa\n",
      "* http://en.wikipedia.org/wiki/List_of_countries_by_past_and_future_population"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import urllib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import yaml\n",
      "credentials = yaml.load(open('kimono_api_key.yaml'))\n",
      "api_key = credentials['KIMONO_KEY']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = json.load(urllib.urlopen(\"https://www.kimonolabs.com/api/5ujg54qa?apikey=\" + api_key))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_hacker_news_jobs(api_key):\n",
      "    \"\"\"\n",
      "    Creates list of top 50 movies by gross box office\n",
      "    sales for a year with ratings and sales\n",
      "    \"\"\"\n",
      "    \n",
      "    title_text, title_url = [], []\n",
      "    url = \"https://www.kimonolabs.com/api/5ujg54qa?\" + \\\n",
      "            \"apikey={api_key}\".format(api_key=api_key)\n",
      "    \n",
      "    data = json.load(urllib.urlopen(url))\n",
      "# Iterate through json object to collect data\n",
      "    for n in xrange(data['count']):\n",
      "        n_text = data['results']['collection1'][n]['title']['text']\n",
      "        n_url = data['results']['collection1'][n]['title']['href']\n",
      "        title_text.append(n_text)\n",
      "        title_url.append(n_url)\n",
      "    \n",
      "    data = pd.DataFrame({'title':title_text,'url':title_url})\n",
      "    \n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_hacker_news_jobs(api_key='6d9YOFeaM8AdNV7LynhlkpuWDsdX4FJ7')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Additional Resources\n",
      "\n",
      "http://help.kimonolabs.com/hc/en-us/articles/203489400-Tutorial-Retrieve-large-data-sets-with-more-than-2500-results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}